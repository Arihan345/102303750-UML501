# -*- coding: utf-8 -*-
"""Assignment-3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q1MBD0ZpXnAjEM4UH3kAiTbQ3RpUcl0G
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

url = 'https://drive.google.com/uc?id=1O_NwpJT-8xGfU_-3llUl2sgPu0xllOrX'
df = pd.read_csv(url)

print(df.columns)

X = df.drop(columns=['Avg. Area House Age'])
y = df['Avg. Area House Age']


scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

kf = KFold(n_splits=5, shuffle=True, random_state=1)
best_beta = None
best_r2_score = -np.inf

for train_index, test_index in kf.split(X_scaled):
   X_train, X_test = X_scaled[train_index], X_scaled[test_index]
   y_train, y_test = y.iloc[train_index], y.iloc[test_index]

   beta = np.linalg.inv(X_train.T @ X_train) @ X_train.T @ y_train
   y_pred = X_test @ beta
   r2 = r2_score(y_test, y_pred)

   if r2 > best_r2_score:
       best_r2_score = r2
       best_beta = beta

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=1)
y_pred_final = X_test @ best_beta
final_r2_score = r2_score(y_test, y_pred_final)


print("Best Beta (ùõΩ) Matrix:\n", best_beta)
print("Final R¬≤ Score on 30% test data:", final_r2_score)

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score

url = 'https://drive.google.com/uc?id=1O_NwpJT-8xGfU_-3llUl2sgPu0xllOrX'
df = pd.read_csv(url)

X = df.drop(columns=['Avg. Area House Age'])
y = df['Avg. Area House Age']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train_val, X_test, y_train_val, y_test = train_test_split(
   X_scaled, y, test_size=0.3, random_state=1
)
X_train, X_val, y_train, y_val = train_test_split(
   X_train_val, y_train_val, test_size=0.2, random_state=1
)

def gradient_descent(X, y, learning_rate, iterations):
   n_features = X.shape[1]
   beta = np.zeros(n_features)
   for _ in range(iterations):
       y_pred = X @ beta
       gradient = (1 / len(y)) * X.T @ (y_pred - y)
       beta = beta - learning_rate * gradient
   return beta

learning_rates = [0.001, 0.01, 0.1, 1]
best_beta = None
best_r2_val = -np.inf

for lr in learning_rates:
   beta = gradient_descent(X_train, y_train, lr, iterations=1000)
   y_pred_val = X_val @ beta
   r2_val = r2_score(y_val, y_pred_val)

   print(f"Learning Rate: {lr}, Validation R2 Score: {r2_val}")

   if r2_val > best_r2_val:
       best_r2_val = r2_val
       best_beta = beta


y_pred_test = X_test @ best_beta
final_r2_score = r2_score(y_test, y_pred_test)

print("\nBest Beta (ùõΩ) Matrix:\n", best_beta)
print("Final R¬≤ Score on 30% test data:", final_r2_score)

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score

url = "https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data"
column_names = ["symboling", "normalized_losses", "make", "fuel_type", "aspiration", "num_doors", "body_style",
               "drive_wheels", "engine_location", "wheel_base", "length", "width", "height", "curb_weight",
               "engine_type", "num_cylinders", "engine_size", "fuel_system", "bore", "stroke",
               "compression_ratio", "horsepower", "peak_rpm", "city_mpg", "highway_mpg", "price"]
df = pd.read_csv(url, header=None, names=column_names, na_values=['?'])

for col in df.columns:
   if df[col].dtype == 'object':
       df[col] = df[col].fillna(df[col].mode()[0])
   else:
       df[col] = df[col].fillna(df[col].mean())

df.dropna(subset=['price'], inplace=True)

num_word_mapping = {'two': 2, 'three': 3, 'four': 4, 'five': 5, 'six': 6, 'eight': 8, 'twelve': 12}
df['num_doors'] = df['num_doors'].map(num_word_mapping)
df['num_cylinders'] = df['num_cylinders'].map(num_word_mapping)

categorical_cols = ["body_style", "drive_wheels", "engine_location", "engine_type", "fuel_system", "make", "aspiration", "fuel_type"]
df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

X = df.drop(columns=['price'])
y = df['price']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

model = LinearRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
r2 = r2_score(y_test, y_pred)

print("R-squared:", r2)