# -*- coding: utf-8 -*-
"""Assignment-2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-bACyr3qHAH4QVoD0gCrIosh5vpoLGop
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.impute import SimpleImputer
from datetime import datetime


df = pd.read_csv('AWCustomers.csv')

df['BirthDate'] = pd.to_datetime(df['BirthDate'], errors='coerce')
current_year = datetime.now().year
df['Age'] = current_year - df['BirthDate'].dt.year

selected_features = [
    'YearlyIncome', 'TotalChildren', 'NumberChildrenAtHome', 'Education',
    'Occupation', 'HomeOwnerFlag', 'NumberCarsOwned',
    'Age', 'Gender', 'MaritalStatus'
]

df_selected = df[selected_features].copy()

df_selected.rename(columns={
    'YearlyIncome': 'Yearly Income',
    'TotalChildren': 'Total Children',
    'NumberChildrenAtHome': 'Children At Home',
    'HomeOwnerFlag': 'Home Owner',
    'NumberCarsOwned': 'Cars Owned',
}, inplace=True)


df_processed = df_selected.copy()

numeric_cols = df_processed.select_dtypes(include=np.number).columns
categorical_cols = df_processed.select_dtypes(include='object').columns

num_imputer = SimpleImputer(strategy='median')
df_processed[numeric_cols] = num_imputer.fit_transform(df_processed[numeric_cols])

cat_imputer = SimpleImputer(strategy='most_frequent')
df_processed[categorical_cols] = cat_imputer.fit_transform(df_processed[categorical_cols])

scaler = MinMaxScaler()
df_processed['Yearly Income Normalized'] = scaler.fit_transform(df_processed[['Yearly Income']])

df_processed['Age Binned'] = pd.cut(df_processed['Age'], bins=4, labels=['Young', 'Middle-Aged', 'Senior', 'Elderly'])

std_scaler = StandardScaler()
df_processed['Yearly Income Standardized'] = std_scaler.fit_transform(df_processed[['Yearly Income']])

categorical_features = df_processed.select_dtypes(include=['object', 'category']).columns.drop('Age Binned')
df_encoded = pd.get_dummies(df_processed, columns=categorical_features, drop_first=True)

print("--- Preprocessing Complete ---")
print("Shape of the final, fully encoded DataFrame:", df_encoded.shape)
print(df_encoded.head())


customer_1 = df_encoded.iloc[0]
customer_2 = df_encoded.iloc[1]

binary_cols = [col for col in df_encoded.columns if df_encoded[col].isin([0, 1]).all()]
smc_matches = np.sum(customer_1[binary_cols] == customer_2[binary_cols])
smc = smc_matches / len(binary_cols)

intersection = np.logical_and(customer_1[binary_cols], customer_2[binary_cols]).sum()
union = np.logical_or(customer_1[binary_cols], customer_2[binary_cols]).sum()
jaccard = intersection / union if union != 0 else 0

numeric_features_for_sim = ['Yearly Income Standardized', 'Age', 'Total Children']
vec1 = customer_1[numeric_features_for_sim].values.reshape(1, -1)
vec2 = customer_2[numeric_features_for_sim].values.reshape(1, -1)
cosine_sim = cosine_similarity(vec1, vec2)

print("\n\n--- Proximity Analysis Results ---")
print(f"Simple Matching Coefficient between customer 0 and 1: {smc:.4f}")
print(f"Jaccard Similarity between customer 0 and 1: {jaccard:.4f}")
print(f"Cosine Similarity between customer 0 and 1: {cosine_sim[0][0]:.4f}")

correlation = df_processed['Yearly Income'].corr(df_processed['Cars Owned'])

print("\n\n--- Correlation Analysis Result ---")
print(f"The Pearson correlation between 'Yearly Income' and 'Cars Owned' is: {correlation:.4f}")